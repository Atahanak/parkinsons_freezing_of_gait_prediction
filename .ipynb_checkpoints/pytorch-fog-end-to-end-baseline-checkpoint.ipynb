{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Solution: Rolling Window\n",
    "Here we introduce a pytorch solution which takes an window of past and future Acc readings to predict the outcomes. The different segments of the notebook can be modified and improved as per your liking to better the whole pipeline. As a way, this works as a good starter baseline!\n",
    "\n",
    "**Please leave an upvote if you found this notebook helpful!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-16T19:55:37.989357Z",
     "iopub.status.busy": "2023-03-16T19:55:37.988433Z",
     "iopub.status.idle": "2023-03-16T19:55:41.101003Z",
     "shell.execute_reply": "2023-03-16T19:55:41.099926Z",
     "shell.execute_reply.started": "2023-03-16T19:55:37.989302Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import random\n",
    "import time\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedGroupKFold\n",
    "from sklearn.metrics import accuracy_score, average_precision_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T20:26:48.411830Z",
     "iopub.status.busy": "2023-03-16T20:26:48.411457Z",
     "iopub.status.idle": "2023-03-16T20:26:48.418564Z",
     "shell.execute_reply": "2023-03-16T20:26:48.417255Z",
     "shell.execute_reply.started": "2023-03-16T20:26:48.411800Z"
    }
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    train_dir1 = \"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/defog\"\n",
    "    train_dir2 = \"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/tdcsfog\"\n",
    "\n",
    "    batch_size = 2048\n",
    "    window_size = 256\n",
    "    window_future = 32\n",
    "    window_past = window_size - window_future\n",
    "    \n",
    "    model_dropout = 0.3\n",
    "    model_hidden = 768\n",
    "    model_nblocks = 2\n",
    "    \n",
    "    lr = 0.001\n",
    "    num_epochs = 8\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    feature_list = ['AccV', 'AccML', 'AccAP']\n",
    "    label_list = ['StartHesitation', 'Turn', 'Walking']\n",
    "    \n",
    "    \n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T19:55:41.166896Z",
     "iopub.status.busy": "2023-03-16T19:55:41.166243Z",
     "iopub.status.idle": "2023-03-16T19:55:41.177662Z",
     "shell.execute_reply": "2023-03-16T19:55:41.176398Z",
     "shell.execute_reply.started": "2023-03-16T19:55:41.166758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "We use a window comprised of past and future time Acc readings to form our dataset for a particular time instance. In case some portion of the window data is not available, we pad them with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T19:55:47.109687Z",
     "iopub.status.busy": "2023-03-16T19:55:47.109297Z",
     "iopub.status.idle": "2023-03-16T19:55:47.124391Z",
     "shell.execute_reply": "2023-03-16T19:55:47.123204Z",
     "shell.execute_reply.started": "2023-03-16T19:55:47.109653Z"
    }
   },
   "outputs": [],
   "source": [
    "class FOGDataset(Dataset):\n",
    "    def __init__(self, fpaths, scale=9.806, test=False):\n",
    "        super(FOGDataset, self).__init__()\n",
    "        tm = time.time()\n",
    "        self.test = test\n",
    "        self.fpaths = fpaths\n",
    "        self.f_ids = [os.path.basename(f)[:-4] for f in self.fpaths]\n",
    "        self.curr_df_idx = 0\n",
    "        self.curr_row_idx = 0\n",
    "        self.dfs = [np.array(pd.read_csv(f)) for f in fpaths]\n",
    "        self.end_indices = []\n",
    "        self.scale = scale\n",
    "        \n",
    "        self.length = 0\n",
    "        for df in self.dfs:\n",
    "            self.length += df.shape[0]\n",
    "            self.end_indices.append(self.length)\n",
    "            \n",
    "        print(f\"Dataset initialized in {time.time() - tm} secs!\")\n",
    "        \n",
    "    def pad(self, df, time_start):\n",
    "        if df.shape[0] == cfg.window_size:\n",
    "            return df\n",
    "        \n",
    "        npad = cfg.window_size - df.shape[0]\n",
    "        padzeros = np.zeros((npad, 3))\n",
    "        if time_start <= 0:\n",
    "            df = np.concatenate((padzeros, df), axis=0)\n",
    "        else:\n",
    "            df = np.concatenate((df, padzeros), axis=0)\n",
    "        return df\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        for i,e in enumerate(self.end_indices):\n",
    "            if index >= e:\n",
    "                continue\n",
    "            df_idx = i\n",
    "            break\n",
    "            \n",
    "        curr_df = self.dfs[i]\n",
    "        row_idx = curr_df.shape[0] - (self.end_indices[i] - index)\n",
    "        _id = self.f_ids[i] + \"_\" + str(row_idx)\n",
    "        \n",
    "        x = self.pad(curr_df[row_idx-cfg.window_past:row_idx+cfg.window_future, 1:4], row_idx-cfg.window_past )\n",
    "        x = torch.tensor(x)/self.scale\n",
    "        \n",
    "        if self.test == True:\n",
    "            return _id, x\n",
    "        \n",
    "        y = curr_df[row_idx, -3:].astype('float')\n",
    "        y = torch.tensor(y)\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified Group K Fold\n",
    "\n",
    "It's mentioned in the data that the subjects are different in the train and test set and even different between the public/private splits of the test data. So we need to use Stratified Group K Fold. But since the positive instances in the sequences are very scarce, we need to pick up the best fold which will give us the best balance of the positive/negative instances. For this notebook, we use only the tdcsfog dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T20:27:04.630484Z",
     "iopub.status.busy": "2023-03-16T20:27:04.629764Z",
     "iopub.status.idle": "2023-03-16T20:27:27.790778Z",
     "shell.execute_reply": "2023-03-16T20:27:27.789644Z",
     "shell.execute_reply.started": "2023-03-16T20:27:04.630447Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 833/833 [00:23<00:00, 36.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 files have positive values in all 3 classes\n",
      "Fold = 0\n",
      "Length of Train = 672, Length of Valid = 161\n",
      "Train classes: 287,832, 1,462,652, 175,633\n",
      "Valid classes: 16,958, 216,130, 32,205\n",
      "Fold = 1\n",
      "Length of Train = 613, Length of Valid = 220\n",
      "Train classes: 51,748, 909,505, 65,242\n",
      "Valid classes: 253,042, 769,277, 142,596\n",
      "Fold = 2\n",
      "Length of Train = 703, Length of Valid = 130\n",
      "Train classes: 271,881, 1,332,746, 183,673\n",
      "Valid classes: 32,909, 346,036, 24,165\n",
      "Fold = 3\n",
      "Length of Train = 649, Length of Valid = 184\n",
      "Train classes: 303,710, 1,517,147, 205,196\n",
      "Valid classes: 1,080, 161,635, 2,642\n",
      "Fold = 4\n",
      "Length of Train = 695, Length of Valid = 138\n",
      "Train classes: 303,989, 1,493,078, 201,608\n",
      "Valid classes: 801, 185,704, 6,230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Analysis of positive instances in each fold of our CV folds\n",
    "\n",
    "n1 = []\n",
    "n2 = []\n",
    "n3 = []\n",
    "\n",
    "# Here I am using the metadata file available during training. Since the code will run again during submission, if \n",
    "# I used the usual file from the competition folder, it would have been updated with the test files too.\n",
    "metadata = pd.read_csv(\"/kaggle/input/copy-train-metadata/tdcsfog_metadata.csv\")\n",
    "\n",
    "for f in tqdm(metadata['Id']):\n",
    "    fpath = f\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/tdcsfog/{f}.csv\"\n",
    "    df = pd.read_csv(fpath)\n",
    "    \n",
    "    n1.append(np.sum(df['StartHesitation']))\n",
    "    n2.append(np.sum(df['Turn']))\n",
    "    n3.append(np.sum(df['Walking']))\n",
    "    \n",
    "print(f\"32 files have positive values in all 3 classes\")\n",
    "\n",
    "metadata['n1'] = n1\n",
    "metadata['n2'] = n2\n",
    "metadata['n3'] = n3\n",
    "\n",
    "sgkf = StratifiedGroupKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "for i, (train_index, valid_index) in enumerate(sgkf.split(X=metadata['Id'], y=[1]*len(metadata), groups=metadata['Subject'])):\n",
    "    print(f\"Fold = {i}\")\n",
    "    train_ids = metadata.loc[train_index, 'Id']\n",
    "    valid_ids = metadata.loc[valid_index, 'Id']\n",
    "    \n",
    "    print(f\"Length of Train = {len(train_ids)}, Length of Valid = {len(valid_ids)}\")\n",
    "    n1_sum = metadata.loc[train_index, 'n1'].sum()\n",
    "    n2_sum = metadata.loc[train_index, 'n2'].sum()\n",
    "    n3_sum = metadata.loc[train_index, 'n3'].sum()\n",
    "    print(f\"Train classes: {n1_sum:,}, {n2_sum:,}, {n3_sum:,}\")\n",
    "    \n",
    "    n1_sum = metadata.loc[valid_index, 'n1'].sum()\n",
    "    n2_sum = metadata.loc[valid_index, 'n2'].sum()\n",
    "    n3_sum = metadata.loc[valid_index, 'n3'].sum()\n",
    "    print(f\"Valid classes: {n1_sum:,}, {n2_sum:,}, {n3_sum:,}\")\n",
    "    \n",
    "# # FOLD 2 is the most well balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T20:27:27.793845Z",
     "iopub.status.busy": "2023-03-16T20:27:27.792763Z",
     "iopub.status.idle": "2023-03-16T20:27:27.835635Z",
     "shell.execute_reply": "2023-03-16T20:27:27.834574Z",
     "shell.execute_reply.started": "2023-03-16T20:27:27.793805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 2\n",
      "Length of Train = 703, Length of Valid = 130\n"
     ]
    }
   ],
   "source": [
    "# The actual train-test split (based on Fold 2)\n",
    "\n",
    "metadata = pd.read_csv(\"/kaggle/input/copy-train-metadata/tdcsfog_metadata.csv\")\n",
    "sgkf = StratifiedGroupKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "for i, (train_index, valid_index) in enumerate(sgkf.split(X=metadata['Id'], y=[1]*len(metadata), groups=metadata['Subject'])):\n",
    "    if i != 2:\n",
    "        continue\n",
    "    print(f\"Fold = {i}\")\n",
    "    train_ids = metadata.loc[train_index, 'Id']\n",
    "    valid_ids = metadata.loc[valid_index, 'Id']\n",
    "    print(f\"Length of Train = {len(train_ids)}, Length of Valid = {len(valid_ids)}\")\n",
    "    \n",
    "    if i == 2:\n",
    "        break\n",
    "        \n",
    "train_fpaths = [f\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/tdcsfog/{_id}.csv\" for _id in train_ids]\n",
    "valid_fpaths = [f\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/tdcsfog/{_id}.csv\" for _id in valid_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T20:27:27.837238Z",
     "iopub.status.busy": "2023-03-16T20:27:27.836878Z",
     "iopub.status.idle": "2023-03-16T20:27:27.846429Z",
     "shell.execute_reply": "2023-03-16T20:27:27.845243Z",
     "shell.execute_reply.started": "2023-03-16T20:27:27.837201Z"
    }
   },
   "outputs": [],
   "source": [
    "def _block(in_features, out_features, drop_rate):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_features, out_features),\n",
    "        nn.BatchNorm1d(out_features),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(drop_rate)\n",
    "    )\n",
    "\n",
    "class FOGModel(nn.Module):\n",
    "    def __init__(self, p=cfg.model_dropout, dim=cfg.model_hidden, nblocks=cfg.model_nblocks):\n",
    "        super(FOGModel, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.in_layer = nn.Linear(cfg.window_size*3, dim)\n",
    "        self.blocks = nn.Sequential(*[_block(dim, dim, p) for _ in range(nblocks)])\n",
    "        self.out_layer = nn.Linear(dim, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, cfg.window_size*3)\n",
    "        x = self.in_layer(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.out_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T20:27:27.849562Z",
     "iopub.status.busy": "2023-03-16T20:27:27.848886Z",
     "iopub.status.idle": "2023-03-16T20:27:27.855665Z",
     "shell.execute_reply": "2023-03-16T20:27:27.854637Z",
     "shell.execute_reply.started": "2023-03-16T20:27:27.849524Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T20:27:27.857862Z",
     "iopub.status.busy": "2023-03-16T20:27:27.857146Z",
     "iopub.status.idle": "2023-03-16T20:27:27.873681Z",
     "shell.execute_reply": "2023-03-16T20:27:27.872561Z",
     "shell.execute_reply.started": "2023-03-16T20:27:27.857823Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    loss_sum = 0.\n",
    "    \n",
    "    model.train()\n",
    "    for x,y in tqdm(loader):\n",
    "        x = x.to(cfg.device).float()\n",
    "        y = y.to(cfg.device).float()\n",
    "        \n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss_sum += loss.item()\n",
    "    \n",
    "    print(f\"Train Loss: {(loss_sum/len(loader)):.04f}\")\n",
    "    \n",
    "\n",
    "def validation_one_epoch(model, loader, criterion):\n",
    "    loss_sum = 0.\n",
    "    y_true_epoch = []\n",
    "    y_pred_epoch = []\n",
    "    \n",
    "    model.eval()\n",
    "    for x,y in tqdm(loader):\n",
    "        x = x.to(cfg.device).float()\n",
    "        y = y.to(cfg.device).float()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "        \n",
    "        loss_sum += loss.item()\n",
    "        y_true_epoch.append(y.cpu().numpy())\n",
    "        y_pred_epoch.append(y_pred.cpu().numpy())\n",
    "        \n",
    "    y_true_epoch = np.concatenate(y_true_epoch, axis=0)\n",
    "    y_pred_epoch = np.concatenate(y_pred_epoch, axis=0)\n",
    "    \n",
    "    scores = [average_precision_score(y_true_epoch[:,i], np.round(y_pred_epoch[:,i],3)) for i in range(3)]\n",
    "    mean_score = np.mean(scores)\n",
    "    print(f\"Validation Loss: {(loss_sum/len(loader)):.04f}, Validation Score: {mean_score:.03f}, ClassWise: {scores[0]:.03f},{scores[1]:.03f},{scores[2]:.03f}\")\n",
    "    \n",
    "    return mean_score\n",
    "        \n",
    "def train():\n",
    "    model = FOGModel().to(cfg.device)\n",
    "    print(f\"Number of parameters in model - {count_parameters(model):,}\")\n",
    "    \n",
    "    train_dataset = FOGDataset(train_fpaths)\n",
    "    valid_dataset = FOGDataset(valid_fpaths)\n",
    "    print(f\"lengths of datasets: train - {len(train_dataset)}, valid - {len(valid_dataset)}\")\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=cfg.batch_size, num_workers=4, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=cfg.batch_size, num_workers=4)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=cfg.lr)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss().to(cfg.device)\n",
    "    \n",
    "    max_score = 0.0\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    for epoch in range(cfg.num_epochs):\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "        score = validation_one_epoch(model, valid_loader, criterion)\n",
    "        \n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            torch.save(model.state_dict(), \"best_model_state.h5\")\n",
    "            print(\"Saving Model ...\")\n",
    "        \n",
    "        print(\"=\"*50)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T20:27:27.876842Z",
     "iopub.status.busy": "2023-03-16T20:27:27.876543Z",
     "iopub.status.idle": "2023-03-16T20:34:02.032065Z",
     "shell.execute_reply": "2023-03-16T20:34:02.030468Z",
     "shell.execute_reply.started": "2023-03-16T20:27:27.876814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in model - 1,777,155\n",
      "Dataset initialized in 5.4231555461883545 secs!\n",
      "Dataset initialized in 0.9551897048950195 secs!\n",
      "lengths of datasets: train - 5963939, valid - 1098733\n",
      "==================================================\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2913/2913 [05:41<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 537/537 [00:43<00:00, 12.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2122, Validation Score: 0.300, ClassWise: 0.052,0.708,0.141\n",
      "Saving Model ...\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "model = train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T20:35:28.193796Z",
     "iopub.status.busy": "2023-03-16T20:35:28.193420Z",
     "iopub.status.idle": "2023-03-16T20:35:34.710448Z",
     "shell.execute_reply": "2023-03-16T20:35:34.709396Z",
     "shell.execute_reply.started": "2023-03-16T20:35:28.193763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset initialized in 0.39499998092651367 secs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [00:05<00:00, 23.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset initialized in 0.01528620719909668 secs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 28.72it/s]\n"
     ]
    }
   ],
   "source": [
    "model = FOGModel().cuda()\n",
    "model.load_state_dict(torch.load(\"/kaggle/working/best_model_state.h5\"))\n",
    "model.eval()\n",
    "\n",
    "test_defog_paths = glob.glob(\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/defog/*.csv\")\n",
    "test_tdcsfog_paths = glob.glob(\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/tdcsfog/*.csv\")\n",
    "\n",
    "test_dataset = FOGDataset(test_defog_paths, test=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=cfg.batch_size, num_workers=0)\n",
    "\n",
    "ids = []\n",
    "preds = []\n",
    "\n",
    "for _id, x in tqdm(test_loader):\n",
    "    x = x.to(cfg.device).float()\n",
    "    with torch.no_grad():\n",
    "        y_pred = torch.clip(model(x)*0.02+1, 0.0, 1.0)\n",
    "    \n",
    "    ids.extend(_id)\n",
    "    preds.extend(list(np.nan_to_num(y_pred.cpu().numpy())))\n",
    "    \n",
    "\n",
    "    \n",
    "test_dataset = FOGDataset(test_tdcsfog_paths, test=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=cfg.batch_size, num_workers=0)\n",
    "    \n",
    "for _id, x in tqdm(test_loader):\n",
    "    x = x.to(cfg.device).float()\n",
    "    with torch.no_grad():\n",
    "        y_pred = torch.clip(model(x)*0.02+1, 0.0, 1.0)\n",
    "    \n",
    "    ids.extend(_id)\n",
    "    preds.extend(list(np.nan_to_num(y_pred.cpu().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T20:41:09.027288Z",
     "iopub.status.busy": "2023-03-16T20:41:09.026886Z",
     "iopub.status.idle": "2023-03-16T20:41:09.223517Z",
     "shell.execute_reply": "2023-03-16T20:41:09.222301Z",
     "shell.execute_reply.started": "2023-03-16T20:41:09.027256Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(286370, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/sample_submission.csv\")\n",
    "sample_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T20:41:21.336239Z",
     "iopub.status.busy": "2023-03-16T20:41:21.335315Z",
     "iopub.status.idle": "2023-03-16T20:41:22.380114Z",
     "shell.execute_reply": "2023-03-16T20:41:22.379034Z",
     "shell.execute_reply.started": "2023-03-16T20:41:21.336186Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = np.array(preds)\n",
    "submission = pd.DataFrame({'Id': ids, 'StartHesitation': np.round(preds[:,0],3), \\\n",
    "                           'Turn': np.round(preds[:,1],3), 'Walking': np.round(preds[:,2],3)})\n",
    "\n",
    "submission = pd.merge(sample_submission[['Id']], submission, how='left', on='Id').fillna(0.0)\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T20:41:31.473508Z",
     "iopub.status.busy": "2023-03-16T20:41:31.472815Z",
     "iopub.status.idle": "2023-03-16T20:41:31.491937Z",
     "shell.execute_reply": "2023-03-16T20:41:31.490668Z",
     "shell.execute_reply.started": "2023-03-16T20:41:31.473469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(286370, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>StartHesitation</th>\n",
       "      <th>Turn</th>\n",
       "      <th>Walking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003f117e14_0</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>003f117e14_1</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003f117e14_2</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003f117e14_3</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003f117e14_4</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id  StartHesitation   Turn  Walking\n",
       "0  003f117e14_0            0.751  0.693     0.71\n",
       "1  003f117e14_1            0.751  0.693     0.71\n",
       "2  003f117e14_2            0.751  0.693     0.71\n",
       "3  003f117e14_3            0.751  0.693     0.71\n",
       "4  003f117e14_4            0.751  0.693     0.71"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(submission.shape)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

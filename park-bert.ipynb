{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedGroupKFold\n",
    "from sklearn.metrics import accuracy_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    DATA_DIR = '../tlvmc-parkinsons-freezing-gait-prediction/'\n",
    "    TRAIN_DIR = '../tlvmc-parkinsons-freezing-gait-prediction/train/'\n",
    "    TDCSFOG_DIR = '../tlvmc-parkinsons-freezing-gait-prediction/train/tdcsfog/'\n",
    "    DEFOG_DIR = '../tlvmc-parkinsons-freezing-gait-prediction/train/defog/'\n",
    "    CHECKPOINT_PATH = './checkpoints/FOGModel/lightning_logs/version_0/checkpoints/epoch=1-step=5826.ckpt'\n",
    "\n",
    "    batch_size = 2048\n",
    "    window_size = 256\n",
    "    window_future = 32\n",
    "    window_past = window_size - window_future\n",
    "\n",
    "    model_dropout = 0.3\n",
    "    model_hidden = 768\n",
    "    model_nblocks = 2\n",
    "\n",
    "    lr = 0.001\n",
    "    num_epochs = 8\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    feature_list = ['AccV', 'AccML', 'AccAP']\n",
    "    label_list = ['StartHesitation', 'Turn', 'Walking']\n",
    "\n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data - Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FOGDataset(Dataset):\n",
    "    def __init__(self, fpaths, scale=9.806, test=False):\n",
    "        super(FOGDataset, self).__init__()\n",
    "        tm = time.time()\n",
    "        self.test = test\n",
    "        self.fpaths = fpaths\n",
    "        self.f_ids = [os.path.basename(f)[:-4] for f in self.fpaths]\n",
    "        self.curr_df_idx = 0\n",
    "        self.curr_row_idx = 0\n",
    "        self.dfs = [np.array(pd.read_csv(f)) for f in fpaths]\n",
    "        self.end_indices = []\n",
    "        self.scale = scale\n",
    "        \n",
    "        self.length = 0\n",
    "        for df in self.dfs:\n",
    "            self.length += df.shape[0]\n",
    "            self.end_indices.append(self.length)\n",
    "            \n",
    "        print(f\"Dataset initialized in {time.time() - tm} secs!\")\n",
    "        \n",
    "    def pad(self, df, time_start):\n",
    "        if df.shape[0] == cfg.window_size:\n",
    "            return df\n",
    "        \n",
    "        npad = cfg.window_size - df.shape[0]\n",
    "        padzeros = np.zeros((npad, 3))\n",
    "        if time_start <= 0:\n",
    "            df = np.concatenate((padzeros, df), axis=0)\n",
    "        else:\n",
    "            df = np.concatenate((df, padzeros), axis=0)\n",
    "        return df\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        for i,e in enumerate(self.end_indices):\n",
    "            if index >= e:\n",
    "                continue\n",
    "            df_idx = i\n",
    "            break\n",
    "            \n",
    "        curr_df = self.dfs[i]\n",
    "        row_idx = curr_df.shape[0] - (self.end_indices[i] - index)\n",
    "        _id = self.f_ids[i] + \"_\" + str(row_idx)\n",
    "        \n",
    "        x = self.pad(curr_df[row_idx-cfg.window_past:row_idx+cfg.window_future, 1:4], row_idx-cfg.window_past )\n",
    "        x = torch.tensor(x)/self.scale\n",
    "        \n",
    "        if self.test == True:\n",
    "            return _id, x\n",
    "        \n",
    "        y = curr_df[row_idx, -3:].astype('float')\n",
    "        y = torch.tensor(y)\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c2fc2f562e45aba281acb83a2d0bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/833 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 files have positive values in all 3 classes\n",
      "Fold = 0\n",
      "Length of Train = 672, Length of Valid = 161\n",
      "Train classes: 287,832, 1,462,652, 175,633\n",
      "Valid classes: 16,958, 216,130, 32,205\n",
      "Fold = 1\n",
      "Length of Train = 613, Length of Valid = 220\n",
      "Train classes: 51,748, 909,505, 65,242\n",
      "Valid classes: 253,042, 769,277, 142,596\n",
      "Fold = 2\n",
      "Length of Train = 703, Length of Valid = 130\n",
      "Train classes: 271,881, 1,332,746, 183,673\n",
      "Valid classes: 32,909, 346,036, 24,165\n",
      "Fold = 3\n",
      "Length of Train = 649, Length of Valid = 184\n",
      "Train classes: 303,710, 1,517,147, 205,196\n",
      "Valid classes: 1,080, 161,635, 2,642\n",
      "Fold = 4\n",
      "Length of Train = 695, Length of Valid = 138\n",
      "Train classes: 303,989, 1,493,078, 201,608\n",
      "Valid classes: 801, 185,704, 6,230\n"
     ]
    }
   ],
   "source": [
    "# Analysis of positive instances in each fold of our CV folds\n",
    "\n",
    "SH = []\n",
    "T = []\n",
    "W = []\n",
    "\n",
    "# Here I am using the metadata file available during training. Since the code will run again during submission, if \n",
    "# I used the usual file from the competition folder, it would have been updated with the test files too.\n",
    "metadata = pd.read_csv(\"../tlvmc-parkinsons-freezing-gait-prediction/tdcsfog_metadata.csv\")\n",
    "\n",
    "for f in tqdm(metadata['Id']):\n",
    "    fpath = f\"../tlvmc-parkinsons-freezing-gait-prediction/train/tdcsfog/{f}.csv\"\n",
    "    df = pd.read_csv(fpath)\n",
    "    \n",
    "    SH.append(np.sum(df['StartHesitation']))\n",
    "    T.append(np.sum(df['Turn']))\n",
    "    W.append(np.sum(df['Walking']))\n",
    "    \n",
    "print(f\"32 files have positive values in all 3 classes\")\n",
    "\n",
    "metadata['SH'] = SH\n",
    "metadata['T'] = T\n",
    "metadata['W'] = W\n",
    "\n",
    "sgkf = StratifiedGroupKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "for i, (train_index, valid_index) in enumerate(sgkf.split(X=metadata['Id'], y=[1]*len(metadata), groups=metadata['Subject'])):\n",
    "    print(f\"Fold = {i}\")\n",
    "    train_ids = metadata.loc[train_index, 'Id']\n",
    "    valid_ids = metadata.loc[valid_index, 'Id']\n",
    "    \n",
    "    print(f\"Length of Train = {len(train_ids)}, Length of Valid = {len(valid_ids)}\")\n",
    "    n1_sum = metadata.loc[train_index, 'SH'].sum()\n",
    "    n2_sum = metadata.loc[train_index, 'T'].sum()\n",
    "    n3_sum = metadata.loc[train_index, 'W'].sum()\n",
    "    print(f\"Train classes: {n1_sum:,}, {n2_sum:,}, {n3_sum:,}\")\n",
    "    \n",
    "    n1_sum = metadata.loc[valid_index, 'SH'].sum()\n",
    "    n2_sum = metadata.loc[valid_index, 'T'].sum()\n",
    "    n3_sum = metadata.loc[valid_index, 'W'].sum()\n",
    "    print(f\"Valid classes: {n1_sum:,}, {n2_sum:,}, {n3_sum:,}\")\n",
    "    \n",
    "# # FOLD 2 is the most well balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 2\n",
      "Length of Train = 703, Length of Valid = 130\n"
     ]
    }
   ],
   "source": [
    "# The actual train-test split (based on Fold 2)\n",
    "\n",
    "metadata = pd.read_csv(cfg.DATA_DIR + \"tdcsfog_metadata.csv\")\n",
    "sgkf = StratifiedGroupKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "for i, (train_index, valid_index) in enumerate(sgkf.split(X=metadata['Id'], y=[1]*len(metadata), groups=metadata['Subject'])):\n",
    "    if i != 2:\n",
    "        continue\n",
    "    print(f\"Fold = {i}\")\n",
    "    train_ids = metadata.loc[train_index, 'Id']\n",
    "    valid_ids = metadata.loc[valid_index, 'Id']\n",
    "    print(f\"Length of Train = {len(train_ids)}, Length of Valid = {len(valid_ids)}\")\n",
    "    \n",
    "    if i == 2:\n",
    "        break\n",
    "        \n",
    "train_fpaths = [f\"{cfg.DATA_DIR}train/tdcsfog/{_id}.csv\" for _id in train_ids]\n",
    "valid_fpaths = [f\"{cfg.DATA_DIR}train/tdcsfog/{_id}.csv\" for _id in valid_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../tlvmc-parkinsons-freezing-gait-prediction/test/tdcsfog/003f117e14.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import glob module \n",
    "import glob\n",
    "# get all the file paths in to list for the test directory\n",
    "test_fpaths = glob.glob(f\"{cfg.DATA_DIR}test/tdcsfog/*.csv\")\n",
    "test_fpaths"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Generalize preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset initialized in 8.142295837402344 secs!\n"
     ]
    }
   ],
   "source": [
    "tdcsfog_train = FOGDataset(train_fpaths)\n",
    "tdcsfog_train_loader = DataLoader(tdcsfog_train, batch_size=cfg.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset initialized in 1.7533018589019775 secs!\n"
     ]
    }
   ],
   "source": [
    "tdcsfog_valid = FOGDataset(valid_fpaths)\n",
    "tdcsfog_valid_loader = DataLoader(tdcsfog_valid, batch_size=cfg.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset initialized in 0.012341022491455078 secs!\n"
     ]
    }
   ],
   "source": [
    "tdcsfog_test = FOGDataset(test_fpaths)\n",
    "tdcsfog_test_loader = DataLoader(tdcsfog_test, batch_size=cfg.batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _block(in_features, out_features, drop_rate):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_features, out_features),\n",
    "        nn.BatchNorm1d(out_features),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(drop_rate)\n",
    "    )\n",
    "\n",
    "class FOGModel(nn.Module):\n",
    "    def __init__(self, p=cfg.model_dropout, dim=cfg.model_hidden, nblocks=cfg.model_nblocks):\n",
    "        super(FOGModel, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.in_layer = nn.Linear(cfg.window_size*3, dim)\n",
    "        self.blocks = nn.Sequential(*[_block(dim, dim, p) for _ in range(nblocks)])\n",
    "        self.out_layer = nn.Linear(dim, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, cfg.window_size*3)\n",
    "        x = self.in_layer(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.out_layer(x)\n",
    "        return x\n",
    "\n",
    "class FOGTransformer(nn.Module):\n",
    "    def __init__(self, p=cfg.model_dropout, dim=cfg.model_hidden, nblocks=cfg.model_nblocks):\n",
    "        super(FOGTransformer, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.in_layer = nn.Linear(cfg.window_size*3, dim)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=dim, nhead=8, dim_feedforward=dim)\n",
    "        self.transformer = nn.TransformerEncoder(self.encoder_layer, num_layers=1, mask_check=False)\n",
    "\n",
    "        self.out_layer = nn.Linear(dim, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, cfg.window_size*3)\n",
    "        x = self.in_layer(x)\n",
    "        x = self.transformer(x)\n",
    "        x = self.out_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 7,686,147 trainable parameters\n",
      "The model has 1,777,155 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "# get the number of parameters in the model\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "model = FOGTransformer()\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "model = FOGModel()\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e949b35cc3244e9a8474ca264e268d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2913 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| y: tensor([[0., 0., 0.],\n",
      "               [0., 0., 0.],\n",
      "               [0., 0., 0.],\n",
      "               ...,\n",
      "               [0., 0., 0.],\n",
      "               [0., 0., 0.],\n",
      "               [0., 0., 0.]], dtype=torch.float64)\n",
      "ic| x.shape: torch.Size([2048, 256, 3])\n",
      "    y.shape: torch.Size([2048, 3])\n",
      "ic| y_hat: tensor([[-0.1651, -0.0484,  0.0436],\n",
      "                   [ 0.4357, -0.1260,  0.0066],\n",
      "                   [ 0.0628, -0.1710, -0.2350],\n",
      "                   ...,\n",
      "                   [ 0.2192,  0.0170, -0.3919],\n",
      "                   [-0.1797,  0.0424, -0.8897],\n",
      "                   [ 0.4158, -0.0130,  0.1014]], grad_fn=<AddmmBackward0>)\n",
      "ic| soft(y_hat): tensor([[0.2980, 0.3349, 0.3671],\n",
      "                         [0.4502, 0.2567, 0.2931],\n",
      "                         [0.3946, 0.3124, 0.2930],\n",
      "                         ...,\n",
      "                         [0.4238, 0.3462, 0.2300],\n",
      "                         [0.3649, 0.4557, 0.1794],\n",
      "                         [0.4199, 0.2735, 0.3066]], grad_fn=<SoftmaxBackward0>)\n",
      "ic| y_hat.shape: torch.Size([2048, 3])\n",
      "ic| y_hat.argmax(dim=-1): tensor([2, 0, 0,  ..., 0, 1, 0])\n",
      "ic| loss.item(): 0.728098802083764\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tdcsfog_train_loader = DataLoader(tdcsfog_train, batch_size=cfg.batch_size, shuffle=True)\n",
    "\n",
    "model = FOGModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cfg.lr)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "soft = nn.Softmax(dim=-1)\n",
    "\n",
    "def train(model, optimizer, criterion, train_loader):\n",
    "    for x, y in tqdm(train_loader):\n",
    "        ic(y)\n",
    "        ic(x.shape, y.shape)\n",
    "        #ic(x, y)\n",
    "        # single forward pass\n",
    "        # cast x to the correct data type\n",
    "        x = x.float()\n",
    "        y_hat = model(x)\n",
    "        ic(y_hat)\n",
    "        ic(soft(y_hat))\n",
    "        ic(y_hat.shape)\n",
    "        ic(y_hat.argmax(dim=-1))\n",
    "        # calculate loss\n",
    "        loss = criterion(y_hat, y)\n",
    "        acc = (y_hat.argmax(dim=-1) == y.argmax(dim=-1)).float().mean()\n",
    "        # calculate gradients\n",
    "        loss.backward()\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "        # print out the loss using ic\n",
    "        ic(loss.item())\n",
    "        break\n",
    "\n",
    "train(model, optimizer, criterion, tdcsfog_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "\n",
    "def create_model(model_name, model_hparams):\n",
    "    if model_name in model_dict:\n",
    "        return model_dict[model_name](**model_hparams)\n",
    "    else:\n",
    "        assert False, f\"Unknown model name \\\"{model_name}\\\". Available models are: {str(model_dict.keys())}\"\n",
    "\n",
    "class FOGModule(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, model, optimizer_name, optimizer_hparams):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            model_name - Name of the model to run. Used for creating the model (see function below)\n",
    "            model_hparams - Hyperparameters for the model, as dictionary.\n",
    "            optimizer_name - Name of the optimizer to use. Currently supported: Adam, SGD\n",
    "            optimizer_hparams - Hyperparameters for the optimizer, as dictionary. This includes learning rate, weight decay, etc.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Exports the hyperparameters to a YAML file, and create \"self.hparams\" namespace\n",
    "        self.save_hyperparameters()\n",
    "        # Create model\n",
    "        self.model = model\n",
    "        # Create loss module\n",
    "        self.loss_module = nn.BCEWithLogitsLoss()\n",
    "        # Example input for visualizing the graph in Tensorboard\n",
    "        self.example_input_array = torch.zeros((1, 256, 3), dtype=torch.float32)\n",
    "\n",
    "    def forward(self, past):\n",
    "        # Forward function that is run when visualizing the graph\n",
    "        return self.model(past)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # We will support Adam or SGD as optimizers.\n",
    "        if self.hparams.optimizer_name == \"Adam\":\n",
    "            # AdamW is Adam with a correct implementation of weight decay (see here for details: https://arxiv.org/pdf/1711.05101.pdf)\n",
    "            optimizer = torch.optim.AdamW(\n",
    "                self.parameters(), **self.hparams.optimizer_hparams)\n",
    "        elif self.hparams.optimizer_name == \"SGD\":\n",
    "            optimizer = torch.optim.SGD(self.parameters(), **self.hparams.optimizer_hparams)\n",
    "        else:\n",
    "            assert False, f\"Unknown optimizer: \\\"{self.hparams.optimizer_name}\\\"\"\n",
    "\n",
    "        # We will reduce the learning rate by 0.1 after 100 and 150 epochs\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "            optimizer, milestones=[100, 150], gamma=0.1)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # \"batch\" is the output of the training data loader.\n",
    "        past, future = batch\n",
    "        past = past.float()\n",
    "        future = future.float()\n",
    "        preds = self.model(past)\n",
    "        loss = self.loss_module(preds, future)\n",
    "        acc = (preds.argmax(dim=-1) == future.argmax(dim=-1)).float().mean()\n",
    "\n",
    "        # Logs the accuracy per epoch to tensorboard (weighted average over batches)\n",
    "        self.log('train_acc', acc, on_step=False, on_epoch=True)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss  # Return tensor to call \".backward\" on\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        past, future = batch\n",
    "        past = past.float()\n",
    "        future = future.float()\n",
    "        preds = self.model(past)\n",
    "        acc = (future.argmax(dim=-1) == preds.argmax(dim=-1)).float().mean()\n",
    "        # By default logs it per epoch (weighted average over batches)\n",
    "        self.log('val_acc', acc)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        past, future = batch\n",
    "        past = past.float()\n",
    "        future = future.float()\n",
    "        preds = self.model(past)\n",
    "        acc = (future == preds.argmax(dim=-1)).float().mean()\n",
    "        # By default logs it per epoch (weighted average over batches), and returns it afterwards\n",
    "        self.log('test_acc', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(module, model, train_loader, val_loader, test_loader, save_name = None, **kwargs):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        model_name - Name of the model you want to run. Is used to look up the class in \"model_dict\"\n",
    "        save_name (optional) - If specified, this name will be used for creating the checkpoint and logging directory.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a PyTorch Lightning trainer with the generation callback\n",
    "    trainer = pl.Trainer(default_root_dir=os.path.join(cfg.CHECKPOINT_PATH, save_name),                          # Where to save models\n",
    "                         accelerator=\"gpu\" if str(cfg.device).startswith(\"cuda\") else \"cpu\",                     # We run on a GPU (if possible)\n",
    "                         devices=1,                                                                          # How many GPUs/CPUs we want to use (1 is enough for the notebooks)\n",
    "                         max_epochs=180,                                                                     # How many epochs to train for if no patience is set\n",
    "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\"),  # Save the best checkpoint based on the maximum val_acc recorded. Saves only weights and not optimizer\n",
    "                                    LearningRateMonitor(\"epoch\")],                                           # Log learning rate every epoch\n",
    "                         enable_progress_bar=True,\n",
    "                         logger = True)                                                           # Set to False if you do not want a progress bar\n",
    "    trainer.logger._log_graph = True         # If True, we plot the computation graph in tensorboard\n",
    "    trainer.logger._default_hp_metric = True # Optional logging argument that we don't need\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(cfg.CHECKPOINT_PATH, save_name + \".ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(f\"Found pretrained model at {pretrained_filename}, loading...\")\n",
    "        model = module.load_from_checkpoint(pretrained_filename) # Automatically loads the model with the saved hyperparameters\n",
    "    else:\n",
    "        pl.seed_everything(42) # To be reproducable\n",
    "        lmodel = module(model, **kwargs)\n",
    "        trainer.fit(lmodel, train_loader, val_loader)\n",
    "        lmodel = module.load_from_checkpoint(trainer.checkpoint_callback.best_model_path) # Load best checkpoint after training\n",
    "\n",
    "    # Test best model on validation and test set\n",
    "    val_result = trainer.test(model, val_loader, verbose=False)\n",
    "    #test_result = trainer.test(model, test_loader, verbose=False)\n",
    "    #result = {\"test\": test_result[0][\"test_acc\"], \"val\": val_result[0][\"test_acc\"]}\n",
    "\n",
    "    return lmodel, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "\n",
      "  | Name        | Type              | Params | In sizes    | Out sizes\n",
      "----------------------------------------------------------------------------\n",
      "0 | model       | FOGModel          | 1.8 M  | [1, 256, 3] | [1, 3]   \n",
      "1 | loss_module | BCEWithLogitsLoss | 0      | ?           | ?        \n",
      "----------------------------------------------------------------------------\n",
      "1.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 M     Total params\n",
      "7.109     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c52e0a10334026b8f9f2b9803904c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c70423e0a5548e39c78fd450e6bdfb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7cf0c79a0f64c8da8a152672563529d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57587e27eec24f87a3376595999fdc84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf70febbc354013a9f50da9bd0058c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed77c84e50e34ed49e4eaad36c7d3ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e4b1c909f749dfb42a457a32bf2d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c56e3e57a36426bbf5d20407de55c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733c446ec42b4df9b2f93c7b4393affe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8c295ee577645a9b33aa6736d99df40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5cbf71be4e4d0aa465795b776b1242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144a6d88a04a436dbaf74278785fef1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b11e8121eea4183b018f4a452aa84a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d83c81e4a04f7e8327cd33db91d849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a3569083a54275ac4b650b74219a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5f6ccd83be4998918df3546f754b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "363c9a40eb1d4138973dd3f6a9b779db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8e3626090a4dc2bdf0139285866982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e963ec7024824135b63cd1151b4f353c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c506aac56fa4be7b78d2fc9508b28ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed6e04a39ef4e83922779c3936b4ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030f60072ed04bd1ae9e06d4d0a3768a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac1843fa27144b08dbbaebd0f72db92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "884130e5d7eb42a7b6c14536ab377e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a04f22e1eca43d0b3e2cb20110e7258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b80a53b7dd4c83b595011898d6a1ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d144658e554a8892e930cebf99a713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231b5486affb4715ab51f7483ab770e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26830f866de3434ba77a65c556235444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a058f96ef440f087ac38794904ba2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d0696bfdac4ea1bcac66ca145f0491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0954dfa6b22044aa8491cffc6879423b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba67e75090e4c4195fd9a0f6f71a007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0c85eaaffec43c3be9f5075ec6b1ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e0fd4f7a0c6417188d30c3137a4d5e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946abe76ca6e49b6a19d4be5273762d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee4be7894014250a60839b6078e559a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9edee389008b4ef9b74a16eedff1fe4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c3308dae79141798e4a2871de3442b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07113b376628476090ce7d0be2cc4bf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e51a55679804a688c4c3dfcd70f5446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff44373082e4db59faa04ed58f157ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf9eff47161430091f171d759528851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eab243f7ce9478c8ed6dcdb2ce92295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a7379bdde43474186d22a322c317b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b250ecd1e84cf684518a816227cc8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235dbf66dab24b2ea2c31276d2800699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05bbe0a1511b4dda8a19d9e87dc11938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986586fe200e44189bfedccde0464986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fddb4c6e84694353b56b927d22733660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a02df5086208407abf3b0fd3b32a8aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "092072d2bfd240fda0ecde978a429ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1627d13efb14fe28f342a754f543435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b090d78bf39b41b78e14294a212a36fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c572aa7b31c4e96839e327b0d68010e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = FOGModel()\n",
    "model, result = train_model(FOGModule, model, tdcsfog_train_loader, tdcsfog_valid_loader, tdcsfog_test_loader, save_name=\"FOGModel\", optimizer_name=\"Adam\", optimizer_hparams={\"lr\": 0.001, \"weight_decay\": 0.0001})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine - Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset initialized in 0.17626714706420898 secs!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "488bdf2b37df4775beb60a8f65ff6687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| sample_submission.shape: (286370, 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(286370, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>StartHesitation</th>\n",
       "      <th>Turn</th>\n",
       "      <th>Walking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003f117e14_0</td>\n",
       "      <td>-1.38156</td>\n",
       "      <td>-0.68742</td>\n",
       "      <td>-1.61269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>003f117e14_1</td>\n",
       "      <td>-1.16376</td>\n",
       "      <td>-0.74558</td>\n",
       "      <td>-1.28099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003f117e14_2</td>\n",
       "      <td>-1.27037</td>\n",
       "      <td>-0.71586</td>\n",
       "      <td>-1.58223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003f117e14_3</td>\n",
       "      <td>-1.45305</td>\n",
       "      <td>-0.81170</td>\n",
       "      <td>-1.47336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003f117e14_4</td>\n",
       "      <td>-1.07444</td>\n",
       "      <td>-0.91191</td>\n",
       "      <td>-1.51292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id  StartHesitation     Turn  Walking\n",
       "0  003f117e14_0         -1.38156 -0.68742 -1.61269\n",
       "1  003f117e14_1         -1.16376 -0.74558 -1.28099\n",
       "2  003f117e14_2         -1.27037 -0.71586 -1.58223\n",
       "3  003f117e14_3         -1.45305 -0.81170 -1.47336\n",
       "4  003f117e14_4         -1.07444 -0.91191 -1.51292"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FOGModel().to(cfg.device)\n",
    "model = FOGModule.load_from_checkpoint(f\"{cfg.CHECKPOINT_PATH}\")\n",
    "#model.eval()\n",
    "\n",
    "test_defog_paths = glob.glob(f\"{cfg.DATA_DIR}test/defog/*.csv\")\n",
    "test_tdcsfog_paths = glob.glob(f\"{cfg.DATA_DIR}test/tdcsfog/*.csv\")\n",
    "#print(test_tdcsfog_paths)\n",
    "test_fpaths = test_defog_paths + test_tdcsfog_paths\n",
    "\n",
    "test_dataset = FOGDataset(test_fpaths, test=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=cfg.batch_size)\n",
    "\n",
    "ids = []\n",
    "preds = []\n",
    "\n",
    "for _id, x in tqdm(test_loader):\n",
    "    x = x.to(cfg.device).float()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(x)*0.1\n",
    "\n",
    "    ids.extend(_id)\n",
    "    preds.extend(list(np.nan_to_num(y_pred.cpu().numpy())))\n",
    "\n",
    "sample_submission = pd.read_csv(f\"{cfg.DATA_DIR}sample_submission.csv\")\n",
    "ic(sample_submission.shape)\n",
    "\n",
    "preds = np.array(preds)\n",
    "submission = pd.DataFrame({'Id': ids, 'StartHesitation': np.round(preds[:,0],5), \\\n",
    "                           'Turn': np.round(preds[:,1],5), 'Walking': np.round(preds[:,2],5)})\n",
    "\n",
    "submission = pd.merge(sample_submission[['Id']], submission, how='left', on='Id').fillna(0.0)\n",
    "submission.to_csv(f\"{cfg.DATA_DIR}submission.csv\", index=False)\n",
    "\n",
    "print(submission.shape)\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parkinson",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
